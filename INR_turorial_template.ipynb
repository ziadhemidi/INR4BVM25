{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "oxWpJ-SC8wt5"
      },
      "source": [
        "# Implicit Neural Representations Tutorial for BVM 2025\n",
        "\n",
        "This tutorial will introduce the concept of Implicit Neural Representations (INRs) and how they can be used in medical image analysis. We will cover the basics of INRs, how they can be used in image reconstruction/representation, denoising and non-linear registration tasks. We will also cover the basics of the [SIREN](https://vsitzmann.github.io/siren/) architecture and how it can be used to implement INRs. Additionally, we will look at a coordinate encoding method that can be used to improve the performance of INRs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OK9fhRj8wt8",
        "outputId": "36797bc5-9c05-48a4-8844-63340f53fdf0"
      },
      "outputs": [],
      "source": [
        "# import and set up the environment\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from IPython.display import clear_output, display\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# # download needed images and files\n",
        "!wget -nc https://cloud.imi.uni-luebeck.de/s/fBnwQNLWXNDqsj5/download -O ct_image_pytorch.pth\n",
        "!wget -nc https://cloud.imi.uni-luebeck.de/s/Njgp9L78KDkJXFj/download -O images_flow.pth\n",
        "!wget -nc https://cloud.imi.uni-luebeck.de/s/85824cEMDK2zbFr/download -O utils.py\n",
        "\n",
        "import utils\n",
        "\n",
        "# set matplotlib them to default\n",
        "plt.style.use('default')\n",
        "\n",
        "# Set device\n",
        "# if nvidia gpu is available use it\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"Using {device}\")\n",
        "# if mps on MacBook is available use it\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
        "    print(f\"Using {device} and setting PYTORCH_ENABLE_MPS_FALLBACK=1\")\n",
        "# fallback to cpu\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(f\"Using {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3po2UZgc8wt9"
      },
      "source": [
        "## 1. Image Reconstruction\n",
        "\n",
        "Implicit neural representations aim to represent a singular data instance, i.e. an image in our case, as a continuous function. This function is represented with a neural network, that gets coordinates as input and is optimized to return the image values at that coordinate. In short, we seek to parameterize a greyscale image $f(x)$ with pixel coordinates $x$ with a neural network $\\Phi$ such that $\\mathcal{L}=\\iint_{\\Omega} \\lVert \\Phi(\\mathbf{x}) - f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x}$ is minimized ($\\Omega$ being the domain of the image).\n",
        "\n",
        "\n",
        "Different from other networks and tasks, an INR network is not trained on a larger training dataset, but should explicitly overfit on that singular data instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75jTFtx68wt-"
      },
      "source": [
        "Let's first load in the image we want to represent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCSyH-Ec8wt-",
        "outputId": "019c527b-ea36-4b9a-f736-1c8d5b902748"
      },
      "outputs": [],
      "source": [
        "img = torch.load('ct_image_pytorch.pth').squeeze()\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "\n",
        "plt.imshow(torch.clamp(img, -500, 500).cpu().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv1IQCsy8wt-"
      },
      "source": [
        "### 1.1. SIREN implementation\n",
        "\n",
        "Implement the [SIREN](https://vsitzmann.github.io/siren/) network architecture. The network always has a first linear layer, a last one, and $n$ hidden layers. The hidden layers are all the same and consist of a linear layer followed by a sine activation function. The last linear layer has no activation.  \n",
        "\n",
        "First implement the SIREN network, which consists of linear layers and sine activations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PezlM5y78wt-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class SIREN(nn.Module):\n",
        "    def __init__(self,in_features, out_features, hidden_ch=256,num_layers=3, scale=30):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        # Todo: initialize the first linear layer\n",
        "        \n",
        "        # Todo: initialize the hidden layers\n",
        "            \n",
        "\n",
        "        # Todo: initialize the last linear layer\n",
        "        \n",
        "\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # Todo: apply the sine function to all the layers multiplied with the scaling factor except the last one\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzHLdv9k8wt-"
      },
      "source": [
        "Furthermore, implement a function that initializes the weights of the linear layers.\n",
        "- The first layer should be initialized with a uniform distribution in the range: $$\\mathcal{U}(-\\frac{1}{fan\\_in}, \\frac{1}{fan\\_in})$$\n",
        "- The hidden layers should be initialized with a uniform distribution in the range: $$\\mathcal{U}(-\\frac{\\sqrt{\\frac{6}{fan\\_in}}}{scale}, \\frac{\\sqrt{\\frac{6}{fan\\_in}}}{scale})$$\n",
        "\n",
        "You can use `torch.nn.init` functions to initialize the weights of the linear layers see the [Documentation](https://pytorch.org/docs/stable/nn.init.html) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYQLIH6c8wt_"
      },
      "outputs": [],
      "source": [
        "def weights_init(m, scale=30):\n",
        "    with torch.no_grad():\n",
        "        # Given: check if the module is a linear layer\n",
        "        if isinstance(m, nn.Linear):\n",
        "            # Shape of the weight matrix: (fan_out, fan_in)\n",
        "            # We want to initialize the weights depending on fan_in\n",
        "            fan_in = \n",
        "            if m.weight.shape[1]>4: # if not first layer\n",
        "                # Todo: calculate the val for the weights initialization\n",
        "               \n",
        "            else:\n",
        "                # Todo: calculate the val for the weights initialization\n",
        "                \n",
        "\n",
        "            # Todo: initialize the weights with uniform distribution between -val and val\n",
        "\n",
        "            # Todo: initialize the bias with zeros\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDo13lIl8wt_"
      },
      "source": [
        "Test your implementation of the SIREN Network with the following: settings in_features = 1, hidden_features = 64, hidden_layers = 3, out_features = 1\n",
        "\n",
        "Call `weights_init` on your network using `.apply` ([Doc](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.apply)).\n",
        "\n",
        "The Network you have implemented should have 12673 parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfgOoVuM8wt_",
        "outputId": "f6d20d0b-f2b1-4b7c-a3b1-143eed895338"
      },
      "outputs": [],
      "source": [
        "# Given: Code to check the number of parameters\n",
        "net = SIREN(in_features=1, out_features=1, hidden_ch=64, num_layers=3)\n",
        "print(net)\n",
        "net.apply(weights_init)\n",
        "print('Parameters:', utils.num_params(net))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jZIfAlU8wt_"
      },
      "source": [
        "### Task 1.2 Coordinate grid\n",
        "\n",
        "Since the input to the SIREN network (INRs) are coordinates, write a function that returns a grid of coordinates for a given size $H\\times W$. The coordinate values should be between -1 and 1.\n",
        "\n",
        "You can do that by using `torch.mehsgrid`, `torch.linspace` and `torch.stack`.\n",
        "Alternatively, you can do that in one step using `torch.nn.functional.affine_grid` and `torch.eye`.\n",
        "\n",
        "The grid should be reshaped to a vector of shape $H*W\\times 2$, where $N$ ist the number of pixels in the image (use `.view`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brvFtD3S8wt_"
      },
      "outputs": [],
      "source": [
        "# create_grid (H,W): create coordinate grid of size HxW\n",
        "def create_grid(H,W):\n",
        "    # Todo: create a grid of size HxW with coordinates in the range [-1,1]\n",
        "    coords = None\n",
        "\n",
        "    return coords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naaVU2cx8wuA",
        "outputId": "9960d604-c3ad-4d77-c448-3f2d99c223e6"
      },
      "outputs": [],
      "source": [
        "# Given: Test your function to create an example grid of size 100 x 100\n",
        "coords = create_grid(100,100)\n",
        "print(coords.shape)\n",
        "plt.scatter(coords[:, 0], coords[:, 1], s=1.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkH31P3F8wuA"
      },
      "source": [
        "### Task 1.3 Training\n",
        "Now you can implement the training routine to reconstruct the image. The loss function should be the mean squared error between the predicted and the ground truth image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9rB3I828wuA",
        "outputId": "44dcd449-6685-4f07-9746-147c6a8be333"
      },
      "outputs": [],
      "source": [
        "# Given: optimization setup\n",
        "num_iters = 100\n",
        "lr = 1e-3\n",
        "H, W = img.shape\n",
        "\n",
        "# Todo: create a 2D grid of coordinates with the same size as the image\n",
        "coordinates = None\n",
        "\n",
        "# Todo: create a SIREN Network with the following settings\n",
        "# in_features = 2, hidden_features = 256, hidden_layers = 3, out_features = 1\n",
        "# The Network you have implemented should have 198401 parameters\n",
        "net = None\n",
        "\n",
        "print('Parameters:', utils.num_params(net))\n",
        "\n",
        "# Todo: initialize the weights of the network\n",
        "\n",
        "\n",
        "# Todo: initialize the optimizer with the parameters of the network and a learning rate of 1e-3\n",
        "optimizer = None\n",
        "\n",
        "# Todo: normalize image by its maximum value and minimum value and move it to the device\n",
        "scale_min, scale_max = None, None\n",
        "img_normed = None\n",
        "\n",
        "# Given: plotting\n",
        "fig, ax = plt.subplots(1, 4, figsize=(24, 5))\n",
        "labels = ['Reconstructed Image', 'Ground Truth', 'Difference: Ground Truth - Reconstructed', 'Loss']\n",
        "for i in range(4):\n",
        "    ax[i].set_title(labels[i])\n",
        "    if i != 3:\n",
        "        ax[i].set_axis_off()\n",
        "ax[3].set_xlim(0, num_iters)\n",
        "\n",
        "\n",
        "# statistics\n",
        "running_loss = []\n",
        "\n",
        "for i in range(num_iters):\n",
        "\n",
        "    # Todo: reset the gradients of the optimizer\n",
        "    \n",
        "\n",
        "    # Todo: forward pass of the network\n",
        "    siren_recon = None\n",
        "\n",
        "    # Todo: calculate the loss\n",
        "    loss =  None\n",
        "\n",
        "    # Todo: backward pass and update the weights\n",
        "\n",
        "    running_loss.append(loss.item())\n",
        "    if i % 10 == 0 or i == num_iters - 1:\n",
        "        print('Iteration %d    Loss %.4f' % (i, loss.item()))\n",
        "        ax[0].imshow(torch.clamp(siren_recon.detach().cpu().reshape(H, W) * (scale_max-scale_min) + scale_min, -500, 500), cmap='gray')\n",
        "        ax[1].imshow(torch.clamp(img, -500, 500), cmap='gray')\n",
        "        ax[2].imshow((utils.normalize(img) - utils.normalize(siren_recon.detach().cpu().reshape(H, W) * (scale_max-scale_min) + scale_min)).abs(), vmin=0, vmax=1, cmap='jet')\n",
        "        ax[3].plot(running_loss, 'r')\n",
        "        display(fig); plt.close()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTOEfYeA8wuA"
      },
      "source": [
        "### Why the periodic activation function?\n",
        "In other networks ReLU, sigmoid or tanh are very common activation function. For INRs this however bears some problems.\n",
        "The coordinate input for nearby voxels differs only slightly. When applying only linear layers and those activations, we can also only obtain a smooth curve as output. This prohibits us from representing higher-dimensional properties (e.g. edges) of the image properly.\n",
        "\n",
        "To demonstrate the difference, create a class `MLP` that is identical to the `SIREN` class except for the nonlinearity: Use `F.relu` instead of the scaled sinus function. Then just copy the training above and use the simple MLP+ReLU network instead of the siren network. You'll see the simple ReLU network doesn't have the capacity to represent high-dimensional features and only finds an extremely low-dimensional fit for the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNL8PCRm8wuA",
        "outputId": "26f96873-f37f-415b-ff31-04f6060004c1"
      },
      "outputs": [],
      "source": [
        "# Todo: copy the training from above and change SIREN to MLP\n",
        "class MLP(SIREN):\n",
        "    def forward(self,x):\n",
        "        #TODO: Remove the sinusoidal activation from SIREN and change them to F.relu\n",
        "        return x\n",
        "\n",
        "# Given: optimization setup\n",
        "num_iters = 100\n",
        "lr = 1e-3\n",
        "H, W = img.shape\n",
        "\n",
        "# Todo: create a 2D grid of coordinates with the same size as the image using your create_grid function\n",
        "coordinates = None\n",
        "\n",
        "# Todo: create a Network with the following settings\n",
        "# in_features = 2, hidden_features = 256, hidden_layers = 3, out_features = 1\n",
        "# The Network you have implemented should have 198401 parameters\n",
        "net = None\n",
        "\n",
        "# Give: print the number of parameters of the network\n",
        "print('Parameters:', utils.num_params(net))\n",
        "print(net)\n",
        "\n",
        "# Todo: normalize image by its maximum value and minimum value and move it to the device\n",
        "scale_min, scale_max = None, None\n",
        "img_normed = None\n",
        "\n",
        "# Todo: initialize the optimizer with the parameters of the network and a learning rate of 1e-3\n",
        "optimizer = None\n",
        "\n",
        "# Given: plotting\n",
        "fig, ax = plt.subplots(1, 4, figsize=(24, 5))\n",
        "labels = ['Reconstructed Image', 'Ground Truth', 'Difference: Ground Truth - Reconstructed', 'Loss']\n",
        "for i in range(4):\n",
        "    ax[i].set_title(labels[i])\n",
        "    if i != 3:\n",
        "        ax[i].set_axis_off()\n",
        "ax[3].set_xlim(0, num_iters)\n",
        "\n",
        "\n",
        "# statistics\n",
        "running_loss = []\n",
        "\n",
        "for i in range(num_iters):\n",
        "\n",
        "    # Todo: reset the gradients of the optimizer\n",
        "    \n",
        "\n",
        "    # Todo: forward pass of the network\n",
        "    reluMLP_recon = None\n",
        "\n",
        "    # Todo: calculate the loss\n",
        "    loss = None\n",
        "\n",
        "    # Todo: backward pass and update the weights\n",
        "\n",
        "    running_loss.append(loss.item())\n",
        "    if i % 10 == 0 or i == num_iters - 1:\n",
        "        print('Iteration %d    Loss %.4f' % (i, loss.item()))\n",
        "        ax[0].imshow(torch.clamp(reluMLP_recon.detach().cpu().reshape(H, W) * (scale_max - scale_min) + scale_min, -500, 500), cmap='gray')\n",
        "        ax[1].imshow(torch.clamp(img, -500, 500), cmap='gray')\n",
        "        ax[2].imshow((utils.normalize(img) - utils.normalize(reluMLP_recon.detach().cpu().reshape(H, W) * (scale_max - scale_min) + scale_min)).abs(), vmin=0, vmax=1, cmap='jet')\n",
        "        ax[3].plot(running_loss, 'r')\n",
        "        display(fig); plt.close()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB2AyRjn8wuA"
      },
      "source": [
        "Compare the results of the SIREN and MLP network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qn27JEr8wuA",
        "outputId": "c96d7b99-6303-4f84-f220-c0812fd633aa"
      },
      "outputs": [],
      "source": [
        "# Given: compare the results of siren and mlp networks by calculating their ssim and psnr values and plot the images\n",
        "siren_recon = siren_recon.detach().cpu().reshape(H, W)\n",
        "reluMLP_recon = reluMLP_recon.detach().cpu().reshape(H, W)\n",
        "\n",
        "img_list = [ siren_recon, reluMLP_recon]\n",
        "titles = ['SIREN', 'MLP']\n",
        "utils.plot_comparison(img, img_list, titles)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KljyE8u8wuB"
      },
      "source": [
        "### Other approaches\n",
        "Aside from SIREN, there are further approaches to properly represent higher-dimensional images. Other activation functions than sinusoidal, e.g. [wavelets](https://openaccess.thecvf.com/content/CVPR2023/papers/Saragadam_WIRE_Wavelet_Implicit_Neural_Representations_CVPR_2023_paper.pdf) or gaussian, can work.\n",
        "\n",
        "Furthermore, instead of changing the activation function, one can directly transform the input through e.g. a [fourier feature mapping](https://arxiv.org/pdf/2006.10739) or hashing grid encoding to obtain a better representation of higher frequencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "YDjDjgo38wuC"
      },
      "source": [
        "## Task 1.4 Fourier Feature encoding\n",
        "\n",
        "<center width=\"100%\" style=\"padding:25px\"><img src=\"https://bmild.github.io/fourfeat/img/teaser.png\" width=\"1000px\"></center>\n",
        "\n",
        "In contrast to using Sinusoidal or Wavelet activation functions we can employ a positional encoder such as [Fourier Features](https://bmild.github.io/fourfeat/) to the coordinates to improve the convergence of high frequencies of a simple ReLU MLP, making it achieve a performance comparable to SIREN or WIRE networks.\n",
        "In this bonus task, we will implement the Fourier feature mapping, which is based on the Bochnerâ€™s theorem to approximate shift-invariant kernels. Here we are going to use random Fourier features to approximate the Gaussian kernel. The Fourier features map the coordinates to a high-dimensional feature space $\\gamma(\\mathbf{v}): \\mathbb{R}^D -> \\mathbb{R}^{\\mathcal{F}}$, where $D$ is the dimensionality of the input coordinates and $\\mathcal{F}$ is the dimensionality of the feature space.\n",
        "\n",
        "The Fourier features are computed as follows:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\gamma(\\mathbf{v})=[\\cos (2 \\pi \\mathbf{B v}), \\sin (2 \\pi \\mathbf{B v})]^{\\mathrm{T}}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where $\\mathbf{B}$ is sampled from a Gaussian distribution $\\mathbf{B}_i \\sim \\mathcal{N}(0, \\sigma^2 \\mathbf{I})$ and $\\gamma(\\mathbf{v})$ is the Fourier feature of the coordinate $\\mathbf{v}$. The scale $\\sigma^2$ of the Gaussian matrix helps us control the amount of underfitting/overfitting on high-frequency details.\n",
        "\n",
        "Hint, you can use:\n",
        "- `torch.randn` to sample from a Gaussian distribution.\n",
        "- `torch.matmul` can be used to multiply two tensors.\n",
        "- `torch.cat` can be used to concatenate tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLhjH6NN8wuC"
      },
      "source": [
        "### Fourier Feature implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH5bBAza8wuC"
      },
      "outputs": [],
      "source": [
        "# Given: Class skeleton for FourierFeatures\n",
        "class FourierFeatures(nn.Module):\n",
        "    def __init__(self, coord_dims, num_freqs, scale=1):\n",
        "        super().__init__()\n",
        "        # Given\n",
        "        self.scale = scale\n",
        "        # Ensure that the number of frequencies is even\n",
        "        assert num_freqs % 2 == 0\n",
        "        # Given: calculate the feature dimensions\n",
        "        self.feature_dims = num_freqs // 2\n",
        "\n",
        "        # Todo: initialize the basis matrix B with random values and use the scale factor\n",
        "        self.B = None\n",
        "\n",
        "    def forward(self, coordinates):\n",
        "        # Todo: implement the forward pass based on the formula in the description\n",
        "        features = None\n",
        "        return features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1GrluLd8wuC"
      },
      "source": [
        "Test your implementation on the coordinates. The output should have the shape $HW \\times F$.\n",
        "\n",
        "Your features should look similar to the following image (remember that it is not a 100% match since the features are random):\n",
        "<center width=\"100%\" style=\"padding:25px\"><img src=\"https://cloud.imi.uni-luebeck.de/s/NfMa2P8WEf884F2/download\" width=\"2000px\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIXhuFoe8wuC",
        "outputId": "3390969d-69d0-477b-af23-ce33b2588f8d"
      },
      "outputs": [],
      "source": [
        "# Given: Test your implementation\n",
        "frequency_dim = 256\n",
        "sigma2 = 5\n",
        "\n",
        "ff_encodings = FourierFeatures(coord_dims=2, num_freqs=frequency_dim, scale=sigma2)(coordinates)\n",
        "print('Fourier Encodings:', ff_encodings.shape)\n",
        "ff_encodings = ff_encodings.view(H, W, -1).cpu().detach().numpy()\n",
        "\n",
        "# Given: plot some of the fourier features\n",
        "fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
        "for i in range(5):\n",
        "    ax[i].imshow(ff_encodings[..., i], cmap='jet')\n",
        "    ax[i].set_title(f'Feature {i}')\n",
        "    ax[i].axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOROKDUs8wuH"
      },
      "source": [
        "### Training\n",
        "\n",
        "Now, let's train the ReLU MLP with the Fourier feature mapping. The training routine should be the same as the one for the ReLU MLP network but we encode the coordinates with the Fourier feature mapping before feeding them to the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZrBJ79a8wuH",
        "outputId": "fb975859-7e70-4c54-d7e4-4cfc866f0cde"
      },
      "outputs": [],
      "source": [
        "# Todo: copy the training from above and change SIREN to MLP\n",
        "class MLP(SIREN):\n",
        "    def forward(self,x):\n",
        "        #Todo: Remove the sinusoidal activation from SIREN and change them to F.relu\n",
        "        return x\n",
        "\n",
        "# Given: optimization setup\n",
        "num_iters = 100\n",
        "lr = 1e-3\n",
        "\n",
        "# Todo: create a 2D grid of coordinates with your create_grid function\n",
        "H, W = img.shape\n",
        "coordinates = None\n",
        "\n",
        "# Todo: create a Network with the following settings\n",
        "# in_features = 256 (num_freqs), hidden_features = 256, hidden_layers = 3, out_features = 1\n",
        "# The Network you have implemented should have 198401 parameters\n",
        "net = None\n",
        "\n",
        "\n",
        "# print the number of parameters of the network\n",
        "print('Parameters:', utils.num_params(net))\n",
        "print(net)\n",
        "\n",
        "# Todo: create your FourierFeatures encoding for coordinate_dims=2, num_freqs=256, scale(sigma2)=5\n",
        "encoding = None\n",
        "\n",
        "# Todo: normalize image by its maximum value and minimum value and move it to the device\n",
        "scale_min, scale_max = None, None\n",
        "img_normed = None\n",
        "\n",
        "# Todo: initialize the optimizer with the parameters of the network and a learning rate of 1e-3\n",
        "optimizer = None\n",
        "\n",
        "# plotting\n",
        "fig, ax = plt.subplots(1, 4, figsize=(24, 5))\n",
        "labels = ['Reconstructed Image', 'Ground Truth', 'Difference: Ground Truth - Reconstructed', 'Loss']\n",
        "for i in range(4):\n",
        "    ax[i].set_title(labels[i])\n",
        "    if i != 3:\n",
        "        ax[i].set_axis_off()\n",
        "ax[3].set_xlim(0, num_iters)\n",
        "\n",
        "\n",
        "# statistics\n",
        "running_loss = []\n",
        "\n",
        "for i in range(num_iters):\n",
        "\n",
        "    # Todo: reset the gradients of the optimizer\n",
        "    \n",
        "\n",
        "    # Todo: forward pass of the network with the encoded coordinates\n",
        "    ff_reluMLP_recon = None\n",
        "\n",
        "    # Todo: calculate the loss\n",
        "    loss = None\n",
        "\n",
        "    # Todo: backward pass and update the weights\n",
        "\n",
        "    running_loss.append(loss.item())\n",
        "    if i % 10 == 0 or i == num_iters - 1:\n",
        "        print('Iteration %d    Loss %.4f' % (i, loss.item()))\n",
        "        ax[0].imshow(torch.clamp(ff_reluMLP_recon.detach().cpu().reshape(H, W) * (scale_max-scale_min) + scale_min, -500, 500), cmap='gray')\n",
        "        ax[1].imshow(torch.clamp(img, -500, 500), cmap='gray')\n",
        "        ax[2].imshow((utils.normalize(img) - utils.normalize(ff_reluMLP_recon.detach().cpu().reshape(H, W) * (scale_max-scale_min) + scale_min)).abs(), vmin=0, vmax=1, cmap='jet')\n",
        "        ax[3].plot(running_loss, 'r')\n",
        "        display(fig); plt.close()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9i0Hmpb8wuH"
      },
      "source": [
        "Let's plot the comparison to our results before. We can see now with the Fourier feature mapping the ReLU MLP can represent high-frequency details and achieve a performance comparable to SIREN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qIo5ffy8wuI",
        "outputId": "8d6f2cd2-6b62-4e69-8f07-1667955560cd"
      },
      "outputs": [],
      "source": [
        "ff_reluMLP_recon = ff_reluMLP_recon.detach().cpu().reshape(H, W)\n",
        "img_list = [siren_recon, reluMLP_recon, ff_reluMLP_recon]\n",
        "names = ['SIREN', 'ReLU MLP', 'Fourier Features MLP']\n",
        "utils.plot_comparison(img, img_list, names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjIWzxcZ8wuB"
      },
      "source": [
        "## Task 2: Image Denoising\n",
        "\n",
        "We now want to use the SIREN network to not only reconstruct an image but also remove added noise from it. To achieve that, we add another loss term to our routine that penalizes noise as done in Exercise 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOYHfElD8wuB"
      },
      "source": [
        "First let's add some noise to our image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eid6Vcmn8wuB",
        "outputId": "9a7c70e8-dd60-4e5b-fe8b-f2b703d68f9b"
      },
      "outputs": [],
      "source": [
        "# Given: add noise to the image\n",
        "noisy_img = utils.add_noise(img, 60)\n",
        "\n",
        "# plot the images\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(noisy_img, cmap='gray')\n",
        "plt.title('Noisy Image')\n",
        "plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmpLShbZ8wuB"
      },
      "source": [
        "### Task 2.1 Total Variation\n",
        "Now we implement the [total variation regularization](https://en.wikipedia.org/wiki/Total_variation_denoising) as the sum of the absolute differences between neighboring pixels. You'll need to add the sum for both dimensions. Normalize the result diving by `(Nx - 1) * (Ny - 1)`, Omit any for-loops in your implementation and use clever indexing instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFpemGUR8wuB",
        "outputId": "a8af1c69-7f5f-4c3b-fbe2-cf134404e963"
      },
      "outputs": [],
      "source": [
        "def TVLoss(x):\n",
        "\n",
        "    Nx = x.shape[0]\n",
        "    Ny = x.shape[1]\n",
        "    # Todo: calculate the TVLoss\n",
        "    tv_loss = None\n",
        "    return tv_loss\n",
        "\n",
        "# try out the TVLoss\n",
        "print('TVLoss:', TVLoss(img)) # should return \"TVLoss: tensor(53.9729)\" for the original image\n",
        "print('TVLoss:', TVLoss(noisy_img)) #should be around \"TVLoss: tensor(160.2281)\" for the noisy image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14bvYjoH8wuB"
      },
      "source": [
        "### Task 2.2 Training\n",
        "Slightly change the training for the reconstruction above. The loss should penalize:\n",
        "- the difference between reconstructed image and noisy image\n",
        "- the total variation of the reconstructed image\n",
        "The ratio between both losses should be controlled with a variable `lamda_tv`. Experiment with this value to obtain a suitable result. (Hint: the total variation loss should be weighted less than the image similarity loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6mas8zE8wuB",
        "outputId": "45fa26b8-2ceb-4e28-b6b8-1fa931a4b076"
      },
      "outputs": [],
      "source": [
        "# Optimization setup\n",
        "num_iters = 100\n",
        "lr = 1e-3\n",
        "# Todo: weighting factor for the TVLoss\n",
        "lambda_tv = 0.05\n",
        "\n",
        "# Todo: create a 2D grid of coordinates with your create_grid function\n",
        "H, W = img.shape\n",
        "coordinates = None\n",
        "# Todo: create a SIREN Network with the following settings\n",
        "# in_features = 2, hidden_features = 256, hidden_layers = 3, out_features = 1\n",
        "# The Network you have implemented should have 198401 parameters\n",
        "denoising_siren = None\n",
        "\n",
        "# Todo: initialize the weights of the network\n",
        "\n",
        "# Todo: normalize noisy image by its maximum value and minimum value and move it to the device\n",
        "scale_min, scale_max = None, None\n",
        "noisy_img_normed = None\n",
        "\n",
        "# Todo: initialize the optimizer with the parameters of the network and a learning rate of 1e-3\n",
        "optimizer = None\n",
        "\n",
        "# Given: plotting\n",
        "fig, ax = plt.subplots(1, 5, figsize=(24, 5))\n",
        "labels = ['Noisy Image', 'Denoised Image', 'Ground Truth', 'Difference: Ground Truth - Denoised', 'Loss']\n",
        "for i in range(5):\n",
        "    ax[i].set_title(labels[i])\n",
        "    if i != 4:\n",
        "        ax[i].set_axis_off()\n",
        "ax[4].set_xlim(0, num_iters)\n",
        "\n",
        "\n",
        "# statistics\n",
        "running_loss = []\n",
        "\n",
        "for i in range(num_iters):\n",
        "\n",
        "    # Todo: reset the gradients of the optimizer\n",
        "\n",
        "    # Todo: forward pass of the network\n",
        "    prediction = None\n",
        "\n",
        "    # Todo: calculate the loss\n",
        "    loss = None\n",
        "\n",
        "    # Todo: backward pass and update the weights\n",
        "\n",
        "    running_loss.append(loss.item())\n",
        "    if i % 20 == 0 or i == num_iters - 1:\n",
        "        print('Iteration %d    Loss %.4f' % (i, loss.item()))\n",
        "        ax[0].imshow(torch.clamp(noisy_img_normed.detach().cpu().reshape(H, W) * (scale_max-scale_min) + scale_min, -500, 500), cmap='gray')\n",
        "        ax[1].imshow(torch.clamp(prediction.detach().cpu().reshape(H, W) * (scale_max-scale_min) + scale_min, -500, 500), cmap='gray')\n",
        "        ax[2].imshow(torch.clamp(img, -500, 500), cmap='gray')\n",
        "        ax[3].imshow((utils.normalize(img) - utils.normalize(prediction.detach().cpu().reshape(H, W) * (scale_max-scale_min) + scale_min)).abs(), vmin=0, vmax=1)\n",
        "        ax[4].plot(running_loss, 'r')\n",
        "        display(fig); plt.close()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olOXJRhq8wuB"
      },
      "source": [
        "## Task 3: Registration\n",
        "For the last task, we want to use implicit neural representations to register the following two images.\n",
        "Instead of fitting an image, the INR is now supposed to fit the deformation field. The loss will be the difference between the fixed image and the moving image, that is warped using the deformation field, and a regularization term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCOMzXtg8wuB",
        "outputId": "f57fd589-9a8d-4551-cf19-9b4a61c909a3"
      },
      "outputs": [],
      "source": [
        "# Given\n",
        "if device == 'mps':\n",
        "    device = 'cpu'\n",
        "\n",
        "images = torch.load('images_flow.pth')\n",
        "fixed = images[0:1].unsqueeze(1).to(device)\n",
        "moving = images[1:2].unsqueeze(1).to(device)\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(10,20))\n",
        "ax[0].imshow(fixed.cpu().squeeze(), cmap='gray')\n",
        "ax[0].set_title('fixed')\n",
        "ax[1].imshow(moving.cpu().squeeze(), cmap='gray')\n",
        "ax[1].set_title('moving')\n",
        "dif = ax[2].imshow((moving - fixed).cpu().abs().squeeze(), vmin=0, vmax=200)\n",
        "ax[2].set_title('differences')\n",
        "plt.colorbar(dif, fraction=0.05, pad=0.1)\n",
        "ax[0].axis('off')\n",
        "ax[1].axis('off')\n",
        "ax[2].axis('off')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cKziIDV8wuB"
      },
      "source": [
        "Initialize everything needed for the registration task:\n",
        "- **height and width** parameters $H$, $W$\n",
        "- the **SIREN network**: the network needs to predict a deformation for the x- and y-values, this should be reflected in the number of output features\n",
        "- **coordinate input** of size $HW \\times 2$\n",
        "- an **identity grid** of size $1\\times H \\times W \\times 2$ to add to the deformation field for the warping step (you can initialize this the same way as the coordinates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjTkQxcE8wuB"
      },
      "outputs": [],
      "source": [
        "# Given: Move the images to the device and get the height and width of the images\n",
        "fixed = fixed.to(device)\n",
        "moving = moving.to(device)\n",
        "H,W = fixed.size()[-2:]\n",
        "\n",
        "# Todo: initialize the SIREN network (remember to initialise the weights as well) set hidden_ch=64 and num_layers=3\n",
        "net = None  \n",
        "\n",
        "# Todo: create a 2D grid of coordinates with HxW size, since we are using grid_sample in the training we need to use either affine_grid to create our grid, or using torch.meshgrid but applying .flip(-1) to the output of create_grid() function to match the grid_sample format\n",
        "identity_grid = None  \n",
        "# input coordinates are the same as the identity grid but viewed as HW x 2\n",
        "coordinates = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vbmm7ZB8wuC"
      },
      "source": [
        "### Training\n",
        "\n",
        "Next, implement the training loop.\n",
        "\n",
        "The model output should be used to warp the moving image using `F.grid_sample`. To perform the warping step, add the predefined identity grid to your predicted displacement field (use `.view` on the model output).\n",
        "\n",
        "The loss consists of two parts:\n",
        "- The mean squared error between fixed and warped image.\n",
        "- The mean of the squared gradient of the deformation field. The gradient can be obtained with `torch.gradient` and stacked with `torch.stack`. Perform this separately for the x and y direction (first and second feature dimension of the model output).\n",
        "- The parts can be weighted with a factor (Hint: The Smoothness Factor should be weighted stronger than the image similarity)\n",
        "\n",
        "In the end, you should be able to obtain a smooth displacement field that creates a well fitting warped image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk8ejvyP8wuC",
        "outputId": "7387554d-eee3-4471-8c57-dc0c9349edb8"
      },
      "outputs": [],
      "source": [
        "total_steps = 500\n",
        "steps_til_summary = 100\n",
        "\n",
        "# Todo: Adam optimizer with learning rate 1e-4\n",
        "optim = None\n",
        "\n",
        "# plotting\n",
        "fig, ax = plt.subplots(1, 5, figsize=(24, 5))\n",
        "labels = ['Fixed', 'Warped', 'Moving', 'Displacement Field', 'Loss']\n",
        "for i in range(5):\n",
        "    ax[i].set_title(labels[i])\n",
        "    if i != 4:\n",
        "        ax[i].set_axis_off()\n",
        "ax[4].set_xlim(0, total_steps)\n",
        "\n",
        "running_loss = []\n",
        "\n",
        "for step in range(total_steps):\n",
        "    # Todo: reset gradient\n",
        "\n",
        "    # Todo: get the prediction\n",
        "    model_output = None\n",
        "    # Todo: warp the image\n",
        "    warped = None\n",
        "\n",
        "    # Todo: Compute loss criteria\n",
        "    loss = None\n",
        "    \n",
        "    # Todo: backpropagation and optimizer step\n",
        "\n",
        "    running_loss.append(loss.item())\n",
        "    if step % steps_til_summary == 0 or step == total_steps - 1:\n",
        "        rgb = utils.showFlow(model_output.reshape(1,H,W,2).permute(0,3,1,2).data.cpu())\n",
        "        print('Iteration %d    Loss %.4f' % (step, loss.item()))\n",
        "        ax[0].imshow(fixed.detach().cpu().reshape(H, W), cmap='gray')\n",
        "        ax[1].imshow(warped.detach().cpu().reshape(H, W), cmap='gray')\n",
        "        ax[2].imshow(moving.detach().cpu().reshape(H, W), cmap='gray')\n",
        "        ax[3].imshow(rgb)\n",
        "        ax[4].plot(running_loss, 'r')\n",
        "        display(fig); plt.close()\n",
        "\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
